{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jul/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from phaunos_ml.utils.dataset_utils import create_subset, dataset_stat_per_file, read_dataset_file\n",
    "from phaunos_ml.utils.dataug_utils import tfrecords2dataset_aug, tfrecords2tfdataset, mixup\n",
    "from phaunos_ml.utils.feature_utils import AudioSegmentExtractor\n",
    "#from phaunos_ml.utils.dataset_utils import dataset2tfrecords\n",
    "from phaunos_ml.utils import tf_utils\n",
    "from phaunos_ml.utils.tf_utils import serialized2data\n",
    "from nsb_aad.frame_based_detectors.mario_detector import MarioDetector\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/home/jul/data/xenocanto/'\n",
    "LABEL_FILENAME = '/home/jul/data/xenocanto/labels.csv'\n",
    "SUBSET_PATH = os.path.join(ROOT_PATH, 'custom_subsets')\n",
    "AUDIO_DIRNAME = 'audio/wav_22050hz_MLR'\n",
    "ANNOTATION_DIRNAME = 'annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: {60, 141}\n",
      "/home/jul/data/xenocanto/custom_subsets/subset_1570008079/subset_1570008079.csv\n"
     ]
    }
   ],
   "source": [
    "# create Xeno-Canto data subset with 5 randomly picked classes\n",
    "class_list = sorted([line.strip() for line in open(LABEL_FILENAME, 'r')])\n",
    "subset_label_set = set(np.random.choice(range(len(class_list)), 2, replace=False))\n",
    "print(f'Classes: {subset_label_set}')\n",
    "subset_filename = create_subset(\n",
    "    ROOT_PATH,\n",
    "    ['.'],\n",
    "    SUBSET_PATH,\n",
    "    audio_dirname=AUDIO_DIRNAME,\n",
    "    annotation_dirname=ANNOTATION_DIRNAME,\n",
    "    label_set=subset_label_set)\n",
    "print(subset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:00, 1085.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class index, number of files, total duration (in s)\n",
      " 60 (ardenna_pacifica), 10, 468.887\n",
      " 141 (coracias_garrulus), 9, 298.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Show dataset stats\n",
    "# Note: The total number of instances might be higher than the number of audio files because a file might have multiple labels\n",
    "d_num, d_dur = dataset_stat_per_file(ROOT_PATH, subset_filename)\n",
    "print(\"Class index, number of files, total duration (in s)\") \n",
    "for k, v in sorted(d_num.items()): \n",
    "    print(f' {k} ({class_list[k]}), {v}, {d_dur[k]:<.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_rate': 22050,\n",
       " 'win_length': 512,\n",
       " 'hop_length': 128,\n",
       " 'min_freq': 200,\n",
       " 'max_freq': 11025,\n",
       " 'clipping_threshold': 3,\n",
       " 'opening_kernel_shape': [2, 3],\n",
       " 'median_filter_shape': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configure activity detector\n",
    "config_file_mario = '/home/jul/dev/nature_sound_box/nsb_aad/configs/mario.json'\n",
    "config_mario = json.load(open(config_file_mario, 'r'))\n",
    "mario_detector = MarioDetector(config_mario)\n",
    "config_mario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure audio segment extractor\n",
    "sr = 22050\n",
    "segment_dur = 1\n",
    "segment_hop_dur = 1\n",
    "audio_ex = AudioSegmentExtractor(sr=sr, example_duration=segment_dur, example_hop_duration=segment_hop_dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  2.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate feature\n",
    "from phaunos_ml.utils.dataset_utils import dataset2tfrecords\n",
    "tfrecord_path = os.path.join(os.path.dirname(subset_filename), 'features')\n",
    "dataset2tfrecords(ROOT_PATH,                  \n",
    "                  subset_filename,\n",
    "                  tfrecord_path,\n",
    "                  feature_extractor=audio_ex,\n",
    "                  activity_detector=mario_detector,\n",
    "                  min_activity_dur=0.04,                  \n",
    "                  audio_dirname=AUDIO_DIRNAME,\n",
    "                  annotation_dirname=ANNOTATION_DIRNAME\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1002 11:23:42.366763 140554214725440 deprecation.py:323] From /home/jul/dev/phaunos_ml/phaunos_ml/utils/tf_utils.py:44: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "# check some examples\n",
    "example_filenames = random.sample(os.listdir(os.path.join(tfrecord_path, 'positive', AUDIO_DIRNAME)), 2)\n",
    "example1 = tf_utils.tfrecord2example(os.path.join(tfrecord_path, 'positive', AUDIO_DIRNAME, example_filenames[0]), audio_ex)\n",
    "example2 = tf_utils.tfrecord2example(os.path.join(tfrecord_path, 'positive', AUDIO_DIRNAME, example_filenames[1]), audio_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd4c4787e80>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_ex.plot(example1[0]['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'data': <tf.Tensor: id=99, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-1.5258789e-04,  9.1552734e-04,  1.6479492e-03, ...,\n",
       "          -1.2881470e-01, -1.6336060e-01, -1.2707520e-01]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=100, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=101, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=102, shape=(2,), dtype=float32, numpy=array([0.        , 0.99995464], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=103, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.05209351,  0.02105713,  0.06646729, ..., -0.00491333,\n",
       "          -0.00845337, -0.00512695]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=104, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=105, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=106, shape=(2,), dtype=float32, numpy=array([1.       , 1.9999547], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=107, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[ 0.00180054,  0.01086426,  0.02041626, ..., -0.05065918,\n",
       "          -0.00579834,  0.03756714]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=108, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=109, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=110, shape=(2,), dtype=float32, numpy=array([2.       , 2.9999547], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=111, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[0.06506348, 0.06930542, 0.05108643, ..., 0.00170898, 0.01095581,\n",
       "          0.01559448]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=112, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=113, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=114, shape=(2,), dtype=float32, numpy=array([3.       , 3.9999547], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=115, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[ 0.01333618,  0.00509644, -0.00546265, ...,  0.02172852,\n",
       "           0.02697754,  0.02862549]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=116, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=117, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=118, shape=(2,), dtype=float32, numpy=array([4.       , 4.9999547], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=119, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[ 0.02243042,  0.00772095, -0.0112915 , ..., -0.01037598,\n",
       "          -0.01190186, -0.00662231]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=120, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=121, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=122, shape=(2,), dtype=float32, numpy=array([5.       , 5.9999547], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=123, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.00036621, -0.00180054, -0.00213623, ...,  0.01263428,\n",
       "           0.01754761,  0.00918579]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=124, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=125, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=126, shape=(2,), dtype=float32, numpy=array([7.       , 7.9999547], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=127, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.00585938, -0.01669312, -0.01727295, ..., -0.00308228,\n",
       "          -0.01348877, -0.01123047]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=128, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=129, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=130, shape=(2,), dtype=float32, numpy=array([8.      , 8.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=131, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[ 0.00360107,  0.01989746,  0.02233887, ..., -0.00054932,\n",
       "          -0.00305176, -0.00323486]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=132, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=133, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=134, shape=(2,), dtype=float32, numpy=array([9.      , 9.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=135, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.00161743, -0.00012207,  0.00109863, ..., -0.00411987,\n",
       "           0.01831055,  0.03186035]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=136, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=137, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=138, shape=(2,), dtype=float32, numpy=array([10.      , 10.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=139, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[ 0.02853394,  0.00814819, -0.01782227, ...,  0.00338745,\n",
       "          -0.00259399, -0.00601196]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=140, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=141, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=142, shape=(2,), dtype=float32, numpy=array([11.      , 11.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=143, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.00613403, -0.00311279,  0.00238037, ..., -0.03115845,\n",
       "          -0.01586914,  0.00613403]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=144, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=145, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=146, shape=(2,), dtype=float32, numpy=array([12.      , 12.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=147, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[ 0.02700806,  0.03967285,  0.04034424, ..., -0.04769897,\n",
       "          -0.05010986, -0.02804565]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=148, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=149, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=150, shape=(2,), dtype=float32, numpy=array([13.      , 13.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=151, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[ 0.00531006,  0.03262329,  0.04049683, ..., -0.12713623,\n",
       "          -0.0668335 ,  0.01629639]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=152, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=153, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=154, shape=(2,), dtype=float32, numpy=array([14.      , 14.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=155, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[ 0.08251953,  0.10211182,  0.07327271, ..., -0.01376343,\n",
       "          -0.0319519 , -0.04214478]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=156, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=157, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=158, shape=(2,), dtype=float32, numpy=array([15.      , 15.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=159, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.0430603 , -0.03399658, -0.01821899, ..., -0.0776062 ,\n",
       "           0.04684448,  0.13723755]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=160, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=161, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=162, shape=(2,), dtype=float32, numpy=array([16.      , 16.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=163, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[ 0.14691162,  0.07559204, -0.03399658, ..., -0.03500366,\n",
       "          -0.01263428,  0.01571655]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=164, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=165, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=166, shape=(2,), dtype=float32, numpy=array([17.      , 17.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=167, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[0.03295898, 0.02954102, 0.00894165, ..., 0.00830078, 0.00747681,\n",
       "          0.00085449]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=168, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=169, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=170, shape=(2,), dtype=float32, numpy=array([18.      , 18.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=171, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.00775146, -0.01318359, -0.01263428, ...,  0.00311279,\n",
       "          -0.00570679, -0.0112915 ]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=172, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=173, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=174, shape=(2,), dtype=float32, numpy=array([19.      , 19.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=175, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.01174927, -0.00592041,  0.00357056, ...,  0.06375122,\n",
       "           0.0512085 ,  0.02230835]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=176, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=177, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=178, shape=(2,), dtype=float32, numpy=array([20.      , 20.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=179, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.01541138, -0.05056763, -0.07122803, ...,  0.02612305,\n",
       "           0.02206421,  0.00540161]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=180, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=181, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=182, shape=(2,), dtype=float32, numpy=array([21.      , 21.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=183, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.01583862, -0.03063965, -0.03262329, ..., -0.0067749 ,\n",
       "          -0.04473877, -0.05761719]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=184, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=185, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=186, shape=(2,), dtype=float32, numpy=array([22.      , 22.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=187, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.03979492, -0.00256348,  0.03329468, ...,  0.07592773,\n",
       "           0.08917236,  0.06924438]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=188, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=189, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=190, shape=(2,), dtype=float32, numpy=array([23.      , 23.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=191, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[ 0.02160645, -0.03637695, -0.08255005, ..., -0.02682495,\n",
       "          -0.06271362, -0.07000732]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=192, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=193, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=194, shape=(2,), dtype=float32, numpy=array([24.      , 24.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=195, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.04846191, -0.00949097,  0.03012085, ...,  0.02450562,\n",
       "           0.0112915 , -0.00418091]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=196, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=197, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=198, shape=(2,), dtype=float32, numpy=array([25.      , 25.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=199, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.01190186, -0.01086426, -0.00610352, ...,  0.04745483,\n",
       "           0.04660034,  0.02120972]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=200, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=201, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=202, shape=(2,), dtype=float32, numpy=array([26.      , 26.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=203, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.01483154, -0.04190063, -0.04351807, ..., -0.00393677,\n",
       "           0.01403809,  0.01956177]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=204, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=205, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=206, shape=(2,), dtype=float32, numpy=array([27.      , 27.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=207, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[ 0.01004028, -0.00350952, -0.00921631, ...,  0.03231812,\n",
       "           0.0296936 ,  0.01141357]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=208, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=209, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=210, shape=(2,), dtype=float32, numpy=array([28.      , 28.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=211, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.01245117, -0.0295105 , -0.03070068, ..., -0.01446533,\n",
       "           0.00128174,  0.02041626]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=212, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=213, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=214, shape=(2,), dtype=float32, numpy=array([29.      , 29.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=215, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[ 0.02560425,  0.00970459, -0.01843262, ...,  0.14120483,\n",
       "           0.13287354,  0.06933594]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=216, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=217, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=218, shape=(2,), dtype=float32, numpy=array([30.      , 30.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=219, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[-0.02770996, -0.12039185, -0.17019653, ..., -0.00213623,\n",
       "           0.00167847,  0.00619507]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=220, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=221, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=222, shape=(2,), dtype=float32, numpy=array([31.      , 31.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=223, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[0.00964355, 0.0098877 , 0.0038147 , ..., 0.00164795, 0.00094604,\n",
       "          0.00048828]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=224, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=225, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=226, shape=(2,), dtype=float32, numpy=array([32.      , 32.999954], dtype=float32)>},\n",
       " {'data': <tf.Tensor: id=227, shape=(1, 22050), dtype=float32, numpy=\n",
       "  array([[ 0.00228882,  0.00292969,  0.00064087, ...,  0.02011108,\n",
       "          -0.00863647, -0.03894043]], dtype=float32)>,\n",
       "  'filename': <tf.Tensor: id=228, shape=(), dtype=string, numpy=b'audio/wav_22050hz_MLR/XC380944.R.tf'>,\n",
       "  'labels': <tf.Tensor: id=229, shape=(), dtype=string, numpy=b'141'>,\n",
       "  'times': <tf.Tensor: id=230, shape=(2,), dtype=float32, numpy=array([33.      , 33.999954], dtype=float32)>}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training and augmentation files lists\n",
    "train_files, train_labels = read_dataset_file(\n",
    "    subset_filename,\n",
    "    prepend_path=os.path.join(tfrecord_path, 'positive'),\n",
    "    replace_ext='.tf')\n",
    "aug_files, aug_labels = read_dataset_file(\n",
    "    subset_filename,\n",
    "    prepend_path=os.path.join(tfrecord_path, 'negative'),\n",
    "    replace_ext='.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jul/data/xenocanto/custom_subsets/subset_1570008079/features/positive/audio/wav_22050hz_MLR/XC137486.R.tf, {141}\n"
     ]
    }
   ],
   "source": [
    "print(f'{train_files[3]}, {train_labels[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jul/data/xenocanto/custom_subsets/subset_1570008079/features/negative/audio/wav_22050hz_MLR/XC303133.M.tf, {60}\n"
     ]
    }
   ],
   "source": [
    "print(f'{aug_files[5]}, {aug_labels[5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60, 141]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list = sorted(list(set.union(*train_labels)))\n",
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map to dataset\n",
    "tf_train_files = tf.convert_to_tensor(train_files, dtype=dtypes.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_files = tf.data.Dataset.from_tensor_slices(tf_train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf_train_files.interleave(lambda x: tf.data.TFRecordDataset(x), cycle_length=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((1, 1, 22050), (2,), (), (2,)), types: (tf.float32, tf.float32, tf.string, tf.float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(lambda x: serialized2data(x, audio_ex.feature_shape, class_list, training=False))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_aug = tf.data.TFRecordDataset(aug_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV1 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_aug = dataset_aug.map(lambda x: serialized2data(x, audio_ex.feature_shape, class_list, training=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<lambda>() takes 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-13c198834b41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1771\u001b[0m       return DatasetV1Adapter(\n\u001b[0;32m-> 1772\u001b[0;31m           MapDataset(self, map_func, preserve_cardinality=False))\n\u001b[0m\u001b[1;32m   1773\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m       return DatasetV1Adapter(\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3188\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3189\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3190\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3191\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   3192\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   2553\u001b[0m       \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2554\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2555\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 1355\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1543\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   1546\u001b[0m         self._function_attributes)\n\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                           converted_func)\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2547\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   2548\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2549\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2550\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <lambda>() takes 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda feat, labels: (feat, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((1, 1, 22050), (2,)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
