{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline example\n",
    "\n",
    "Example of standard data pipeline for training neural networks, including feature extraction and writing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phaunos_ml.utils.dataset_utils import read_dataset_file, dataset2tfrecords\n",
    "from phaunos_ml.utils.tf_serialization_utils import serialized2example, serialized2data\n",
    "#from phaunos_ml.utils.dataug_utils import Mixup, time_mask, time_warp, frequency_mask\n",
    "#from phaunos_ml.utils.tf_feature_utils import MelSpectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = './data/birdid_dataset/'\n",
    "BIRDS_DIR = 'birds'\n",
    "NOISE_DIR = 'noise'\n",
    "DATASET_BIRDS_FILE = os.path.join(ROOT_PATH, BIRDS_DIR, 'dataset.csv')\n",
    "LABEL_FILE = os.path.join(ROOT_PATH, BIRDS_DIR, 'labels.csv')\n",
    "DATASET_NOISE_FILE = os.path.join(ROOT_PATH, NOISE_DIR, 'dataset.csv')\n",
    "AUDIO_DIR = 'audio'\n",
    "ANNOTATION_DIR = 'annotations'\n",
    "FEATURE_DIR = 'features'\n",
    "ACTIVITY_DETECTION_CFG = os.path.join(ROOT_PATH, 'activity_detection.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_LIST = [268, 324]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure activity detector\n",
    "\n",
    "Because bird vocalisations are very sparse (e.g. only a few seconds of vocalisations in a 1 min audio file), and we do not want our model to be trained with audio chunks containing no activity, we must detect audio chunks containing activity.\n",
    "\n",
    "Audio chunks containing audio activity will be written to a directory named <b><i>positive</i></b> and audio chunks containing no activity will be written to <b><i>negative</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nsb_aad.frame_based_detectors.mario_detector import MarioDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_rate': 22050,\n",
       " 'win_length': 512,\n",
       " 'hop_length': 128,\n",
       " 'min_freq': 200,\n",
       " 'max_freq': 11025,\n",
       " 'clipping_threshold': 3,\n",
       " 'opening_kernel_shape': [2, 3],\n",
       " 'median_filter_shape': 10}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_detection_cfg = json.load(open(ACTIVITY_DETECTION_CFG, 'r'))\n",
    "activity_detector = MarioDetector(activity_detection_cfg)\n",
    "activity_detection_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure feature extractor\n",
    "\n",
    "We want to use mel-spectrogram as our model input, but because some audio augmentation methods (e.g. Mixup) are applied to the raw audio, we write raw audio chunks of 1s, with no overlap, to the TFRecords, and we will a compute the mel-spectrogram at run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phaunos_ml.utils.feature_utils import AudioSegmentExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_duration = 1 # in seconds\n",
    "segment_hop_duration = 1 # in seconds\n",
    "feature_extractor = AudioSegmentExtractor(\n",
    "    sr=SR,\n",
    "    example_duration=segment_duration,\n",
    "    example_hop_duration=segment_hop_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write data to TFRecords\n",
    "\n",
    "### Write bird TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# audio + annotation files -> TFRecords\n",
    "dataset2tfrecords(\n",
    "        os.path.join(ROOT_PATH, BIRDS_DIR),\n",
    "        DATASET_BIRDS_FILE,\n",
    "        os.path.join(ROOT_PATH, BIRDS_DIR, FEATURE_DIR),\n",
    "        feature_extractor,\n",
    "        activity_detector=activity_detector,\n",
    "        min_activity_dur=0.05,\n",
    "        audio_dirname=AUDIO_DIR,\n",
    "        annotation_dirname=ANNOTATION_DIR,\n",
    "        with_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_birds_path = os.path.join(ROOT_PATH, BIRDS_DIR, FEATURE_DIR, 'positive', AUDIO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(<tf.Tensor: id=155, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.        ,  0.        ,  0.        , ..., -0.00161743,\n",
      "        -0.00491333,  0.00521851]], dtype=float32)>, <tf.Tensor: id=156, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=157, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=158, shape=(2,), dtype=float32, numpy=array([0.        , 0.99995464], dtype=float32)>), (<tf.Tensor: id=159, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.01126099,  0.00332642, -0.00967407, ..., -0.00518799,\n",
      "         0.00216675, -0.00354004]], dtype=float32)>, <tf.Tensor: id=160, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=161, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=162, shape=(2,), dtype=float32, numpy=array([1.       , 1.9999547], dtype=float32)>), (<tf.Tensor: id=163, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.00314331,  0.00900269,  0.00933838, ..., -0.00170898,\n",
      "         0.00875854,  0.00308228]], dtype=float32)>, <tf.Tensor: id=164, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=165, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=166, shape=(2,), dtype=float32, numpy=array([2.       , 2.9999547], dtype=float32)>), (<tf.Tensor: id=167, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.0005188 ,  0.00296021,  0.00714111, ..., -0.0065918 ,\n",
      "        -0.00564575,  0.0071106 ]], dtype=float32)>, <tf.Tensor: id=168, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=169, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=170, shape=(2,), dtype=float32, numpy=array([3.       , 3.9999547], dtype=float32)>), (<tf.Tensor: id=171, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.00674438, -0.00366211, -0.00460815, ..., -0.01062012,\n",
      "        -0.07885742, -0.04760742]], dtype=float32)>, <tf.Tensor: id=172, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=173, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=174, shape=(2,), dtype=float32, numpy=array([4.       , 4.9999547], dtype=float32)>), (<tf.Tensor: id=175, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.02822876,  0.02047729, -0.02685547, ..., -0.00701904,\n",
      "        -0.00454712,  0.00018311]], dtype=float32)>, <tf.Tensor: id=176, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=177, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=178, shape=(2,), dtype=float32, numpy=array([5.       , 5.9999547], dtype=float32)>), (<tf.Tensor: id=179, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.00946045,  0.01449585,  0.00842285, ..., -0.02752686,\n",
      "        -0.06787109,  0.05892944]], dtype=float32)>, <tf.Tensor: id=180, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=181, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=182, shape=(2,), dtype=float32, numpy=array([6.       , 6.9999547], dtype=float32)>), (<tf.Tensor: id=183, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.06246948, -0.04421997, -0.01739502, ..., -0.00393677,\n",
      "        -0.02023315, -0.01293945]], dtype=float32)>, <tf.Tensor: id=184, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=185, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=186, shape=(2,), dtype=float32, numpy=array([7.       , 7.9999547], dtype=float32)>), (<tf.Tensor: id=187, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.00320435,  0.0116272 ,  0.01705933, ...,  0.00170898,\n",
      "         0.0274353 , -0.00384521]], dtype=float32)>, <tf.Tensor: id=188, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=189, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=190, shape=(2,), dtype=float32, numpy=array([8.      , 8.999954], dtype=float32)>), (<tf.Tensor: id=191, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[-0.00878906,  0.00546265, -0.01004028, ...,  0.00234985,\n",
      "        -0.00073242, -0.00228882]], dtype=float32)>, <tf.Tensor: id=192, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=193, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=194, shape=(2,), dtype=float32, numpy=array([9.      , 9.999954], dtype=float32)>), (<tf.Tensor: id=195, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[-0.00094604, -0.00152588,  0.00387573, ..., -0.03485107,\n",
      "        -0.00488281,  0.0413208 ]], dtype=float32)>, <tf.Tensor: id=196, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=197, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=198, shape=(2,), dtype=float32, numpy=array([10.      , 10.999954], dtype=float32)>), (<tf.Tensor: id=199, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.00375366, -0.04925537, -0.01275635, ...,  0.00137329,\n",
      "         0.00228882,  0.00756836]], dtype=float32)>, <tf.Tensor: id=200, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=201, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=202, shape=(2,), dtype=float32, numpy=array([11.      , 11.999954], dtype=float32)>), (<tf.Tensor: id=203, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.00595093,  0.00546265, -0.00448608, ...,  0.17330933,\n",
      "        -0.02294922, -0.17660522]], dtype=float32)>, <tf.Tensor: id=204, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=205, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=206, shape=(2,), dtype=float32, numpy=array([12.      , 12.999954], dtype=float32)>), (<tf.Tensor: id=207, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.07034302,  0.06674194, -0.15002441, ..., -0.00320435,\n",
      "         0.0050354 , -0.0085144 ]], dtype=float32)>, <tf.Tensor: id=208, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=209, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=210, shape=(2,), dtype=float32, numpy=array([13.      , 13.999954], dtype=float32)>), (<tf.Tensor: id=211, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[-0.01095581, -0.00213623, -0.00802612, ..., -0.00210571,\n",
      "         0.00820923,  0.01766968]], dtype=float32)>, <tf.Tensor: id=212, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=213, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=214, shape=(2,), dtype=float32, numpy=array([14.      , 14.999954], dtype=float32)>), (<tf.Tensor: id=215, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.02761841,  0.0234375 ,  0.00689697, ...,  0.00485229,\n",
      "         0.03622437, -0.00350952]], dtype=float32)>, <tf.Tensor: id=216, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=217, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=218, shape=(2,), dtype=float32, numpy=array([15.      , 15.999954], dtype=float32)>), (<tf.Tensor: id=219, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.01287842,  0.01773071, -0.01113892, ..., -0.00720215,\n",
      "        -0.00762939, -0.00479126]], dtype=float32)>, <tf.Tensor: id=220, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=221, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=222, shape=(2,), dtype=float32, numpy=array([16.      , 16.999954], dtype=float32)>), (<tf.Tensor: id=223, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[-0.00689697, -0.00646973, -0.00704956, ...,  0.00271606,\n",
      "         0.0098877 ,  0.0062561 ]], dtype=float32)>, <tf.Tensor: id=224, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=225, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=226, shape=(2,), dtype=float32, numpy=array([17.      , 17.999954], dtype=float32)>), (<tf.Tensor: id=227, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[-0.0039978 , -0.00100708,  0.00485229, ..., -0.00790405,\n",
      "        -0.00708008, -0.00680542]], dtype=float32)>, <tf.Tensor: id=228, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=229, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=230, shape=(2,), dtype=float32, numpy=array([18.      , 18.999954], dtype=float32)>), (<tf.Tensor: id=231, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[-0.00140381,  0.00512695,  0.00930786, ...,  0.02719116,\n",
      "        -0.02059937, -0.01248169]], dtype=float32)>, <tf.Tensor: id=232, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=233, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=234, shape=(2,), dtype=float32, numpy=array([19.      , 19.999954], dtype=float32)>), (<tf.Tensor: id=235, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.02615356, -0.0105896 , -0.00769043, ...,  0.00253296,\n",
      "         0.00296021,  0.00762939]], dtype=float32)>, <tf.Tensor: id=236, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=237, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=238, shape=(2,), dtype=float32, numpy=array([20.      , 20.999954], dtype=float32)>), (<tf.Tensor: id=239, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.00918579,  0.00372314, -0.00119019, ...,  0.00405884,\n",
      "         0.015625  ,  0.02008057]], dtype=float32)>, <tf.Tensor: id=240, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=241, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=242, shape=(2,), dtype=float32, numpy=array([21.      , 21.999954], dtype=float32)>), (<tf.Tensor: id=243, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.01522827,  0.01101685, -0.00274658, ..., -0.0328064 ,\n",
      "        -0.01278687,  0.02203369]], dtype=float32)>, <tf.Tensor: id=244, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=245, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=246, shape=(2,), dtype=float32, numpy=array([22.      , 22.999954], dtype=float32)>), (<tf.Tensor: id=247, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.03302002,  0.01855469,  0.00234985, ..., -0.01434326,\n",
      "        -0.00527954,  0.01107788]], dtype=float32)>, <tf.Tensor: id=248, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=249, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=250, shape=(2,), dtype=float32, numpy=array([23.      , 23.999954], dtype=float32)>), (<tf.Tensor: id=251, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[ 0.01425171,  0.01641846,  0.01553345, ..., -0.0395813 ,\n",
      "         0.09417725,  0.04483032]], dtype=float32)>, <tf.Tensor: id=252, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=253, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=254, shape=(2,), dtype=float32, numpy=array([24.      , 24.999954], dtype=float32)>), (<tf.Tensor: id=255, shape=(1, 22050), dtype=float32, numpy=\n",
      "array([[-0.08944702, -0.06387329,  0.08306885, ...,  0.        ,\n",
      "         0.        ,  0.        ]], dtype=float32)>, <tf.Tensor: id=256, shape=(2,), dtype=float32, numpy=array([0., 1.], dtype=float32)>, <tf.Tensor: id=257, shape=(), dtype=string, numpy=b'audio/XC78163.L.tf'>, <tf.Tensor: id=258, shape=(2,), dtype=float32, numpy=array([25.      , 25.626122], dtype=float32)>)]\n"
     ]
    }
   ],
   "source": [
    "# inspect a random TFRecord\n",
    "# containing the features and labels (shown as one-hot encoded labels)\n",
    "tfrecord_filename = os.path.join(\n",
    "    tfrecord_birds_path,\n",
    "    random.sample(os.listdir(tfrecord_birds_path), 1)[0]\n",
    ")\n",
    "dataset = tf.data.TFRecordDataset([tfrecord_filename])\n",
    "dataset = dataset.map(lambda data: serialized2data(data, CLASS_LIST))\n",
    "data = [d for d in dataset]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write noise TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 758.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# audio + annotation files -> TFRecords\n",
    "dataset2tfrecords(\n",
    "        os.path.join(ROOT_PATH, NOISE_DIR),\n",
    "        DATASET_NOISE_FILE,\n",
    "        os.path.join(ROOT_PATH, NOISE_DIR, FEATURE_DIR),\n",
    "        feature_extractor,\n",
    "        audio_dirname=AUDIO_DIR,\n",
    "        annotation_dirname=ANNOTATION_DIR,\n",
    "        with_labels=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_noise_path = os.path.join(ROOT_PATH, NOISE_DIR, FEATURE_DIR, 'positive', AUDIO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfrecord2data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-95cfeaff777f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfrecord_noise_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfrecord2data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfrecord_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLASS_LIST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfrecord2data' is not defined"
     ]
    }
   ],
   "source": [
    "# inspect a random TFRecord\n",
    "# containing the features only (one-hot labels are all set to 0)\n",
    "tfrecord_filename = os.path.join(\n",
    "    tfrecord_noise_path,\n",
    "    random.sample(os.listdir(tfrecord_noise_path), 1)[0]\n",
    ")\n",
    "data = tfrecord2data(tfrecord_filename, feature_extractor, CLASS_LIST)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make data to feed the model\n",
    "\n",
    "**tf.data.Dataset** is used to get the data from TFRecords.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get bird data\n",
    "\n",
    "Build a dataset providing batches of deserialized, shuffled bird data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of files as a tensor\n",
    "files_bird = [os.path.join(tfrecord_birds_path, f) for f in os.listdir(tfrecord_birds_path)]\n",
    "files_bird = tf.convert_to_tensor(files_bird, dtype=dtypes.string)\n",
    "\n",
    "# convert to tf.data.Dataset\n",
    "files_bird = tf.data.Dataset.from_tensor_slices(files_bird)\n",
    "\n",
    "# interleave the files \n",
    "dataset_bird = files_bird.interleave(lambda x: tf.data.TFRecordDataset(x), cycle_length=2)\n",
    "\n",
    "# deserialize to feature (with shape (1,1,22050)) and\n",
    "# one-hot encoded labels (with shape (2,), i.e. the shape of CLASS_LIST)\n",
    "dataset_bird = dataset_bird.map(lambda x: serialized2data(x, feature_extractor.feature_shape, CLASS_LIST, training=True))\n",
    "\n",
    "# shuffle\n",
    "dataset_bird = dataset_bird.shuffle(100)\n",
    "\n",
    "# batch\n",
    "dataset_bird = dataset_bird.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_bird)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get noise data\n",
    "\n",
    "Build a dataset providing batches of deserialized noise data, to be used in the mixup data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of files as a tensor\n",
    "files_noise = [os.path.join(tfrecord_noise_path, f) for f in os.listdir(tfrecord_noise_path)]\n",
    "\n",
    "# Convert to tf.data.Dataset\n",
    "files_noise = tf.data.TFRecordDataset(files_noise)\n",
    "\n",
    "# Deserialize to feature (with shape (1,1,22050)) and\n",
    "# one-hot encoded labels (with shape (2,), i.e. the shape of CLASS_LIST)\n",
    "dataset_noise = files_noise.map(lambda x: serialized2data(x, feature_extractor.feature_shape, CLASS_LIST, training=True))\n",
    "\n",
    "# Repeat\n",
    "dataset_noise = dataset_noise.repeat()\n",
    "\n",
    "# Make batches\n",
    "dataset_noise = dataset_noise.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-domain data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to the bird data.\n",
    "mixup = Mixup(max_weight=0.4)\n",
    "dataset = tf.data.Dataset.zip((dataset_bird, dataset_noise))\n",
    "dataset = dataset.map(lambda dataset1, dataset2: mixup.process(\n",
    "    dataset1[0], dataset1[1], dataset2[0], dataset2[1], BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute log mel spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FFT = 512\n",
    "HOP_LENGTH = 128\n",
    "FMIN = 50\n",
    "FMAX = 8000\n",
    "N_MELS = 64\n",
    "\n",
    "melspec_ex = MelSpectrogram(SR, N_FFT, HOP_LENGTH, N_MELS, fmin=FMIN, fmax=FMAX, log=True)\n",
    "dataset = dataset.map(lambda data, labels: (\n",
    "    tf.expand_dims(tf.py_function(melspec_ex.process, [tf.squeeze(data)], tf.float32), 1),\n",
    "    labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral-domain data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from channels_first (NCHW) to channels_last (NHWC) format\n",
    "# to match SpecAugment requirement\n",
    "dataset = dataset.map(lambda data, labels: (tf.transpose(data, [0,2,3,1]), labels))\n",
    "\n",
    "# Time warp\n",
    "dataset = dataset.map(lambda data, labels: (tf.py_function(time_warp, [data, 5], tf.float32), labels))\n",
    "\n",
    "# Time masking\n",
    "dataset = dataset.map(lambda data, labels: (tf.py_function(time_mask, [data, 10], tf.float32), labels))\n",
    "\n",
    "# Frequency masking\n",
    "dataset = dataset.map(lambda data, labels: (tf.py_function(frequency_mask, [data, 5], tf.float32), labels))\n",
    "\n",
    "# Back to channels_first (NCHW)\n",
    "dataset = dataset.map(lambda data, labels: (tf.transpose(data, [0,3,1,2]), labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now dataset can be fed to **tf.keras.Model.fit**.\n",
    "\n",
    "Let's see what data the dataset provides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [d[0] for d in dataset]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first example of the first batch.\n",
    "# We can see the effect of data augmentation, namely:\n",
    "# - the noise mixed up with the training data. The only file specified in noise/dataset.csv\n",
    "#   is a pure tone at 4kHz, visible on the spectrogram.\n",
    "# - both time and frequency masking (the vertical line and the horizontal line which is not the 4kHz tone)\n",
    "# - time warping is hard to see, but it's there !\n",
    "\n",
    "librosa.display.specshow(data[0][0,0].numpy(),\n",
    "                         x_coords=None,\n",
    "                         y_coords=None,\n",
    "                         x_axis='time',\n",
    "                         y_axis='mel',\n",
    "                         sr=SR,\n",
    "                         hop_length=HOP_LENGTH,\n",
    "                         fmin=FMIN,\n",
    "                         fmax=FMAX, \n",
    "                         cmap='gray_r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
