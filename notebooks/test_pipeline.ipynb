{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phaunos_ml.utils.dataset_utils import read_dataset_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = './data/birdid_dataset/'\n",
    "BIRDS_DIR = 'birds'\n",
    "NOISE_DIR = 'noise'\n",
    "DATASET_BIRDS_FILE = os.path.join(ROOT_PATH, BIRDS_DIR, 'dataset.csv')\n",
    "LABEL_FILE = os.path.join(ROOT_PATH, BIRDS_DIR, 'labels.csv')\n",
    "AUDIO_DIR = 'audio'\n",
    "ANNOTATION_DIR = 'annotations'\n",
    "FEATURE_DIR = 'features'\n",
    "ACTIVITY_DETECTION_CFG = os.path.join(ROOT_PATH, 'activity_detection.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure activity detector\n",
    "\n",
    "Because bird vocalisations are very sparse (e.g. only a few seconds of vocalisations in a 1 min audio file), and we do not want our model to be trained with audio chunks containing no activity, we must detect audio chunks containing activity.\n",
    "\n",
    "Audio chunks containing audio activity will be written to a directory named <b><i>positive</i></b> and audio chunks containing no activity will be written to <b><i>negative</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nsb_aad.frame_based_detectors.mario_detector import MarioDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_rate': 22050,\n",
       " 'win_length': 512,\n",
       " 'hop_length': 128,\n",
       " 'min_freq': 200,\n",
       " 'max_freq': 11025,\n",
       " 'clipping_threshold': 3,\n",
       " 'opening_kernel_shape': [2, 3],\n",
       " 'median_filter_shape': 10}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_detection_cfg = json.load(open(ACTIVITY_DETECTION_CFG, 'r'))\n",
    "activity_detector = MarioDetector(activity_detection_cfg)\n",
    "activity_detection_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure feature extractor\n",
    "\n",
    "We want to use mel-spectrogram as our model input, but because some audio augmentation methods (e.g. Mixup) are applied to the raw audio, we write raw audio chunks of 1s, with no overlap, to the TFRecords, and we will a compute the mel-spectrogram at run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phaunos_ml.utils.feature_utils import AudioSegmentExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 22050\n",
    "segment_duration = 1 # in seconds\n",
    "segment_hop_duration = 1 # in seconds\n",
    "feature_extractor = AudioSegmentExtractor(\n",
    "    sr=sr,\n",
    "    example_duration=segment_duration,\n",
    "    example_hop_duration=segment_hop_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write bird TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phaunos_ml.utils.dataset_utils import dataset2tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset2tfrecords(\n",
    "        os.path.join(ROOT_PATH, BIRDS_DIR),\n",
    "        DATASET_BIRDS_FILE,\n",
    "        os.path.join(ROOT_PATH, BIRDS_DIR, FEATURE_DIR),\n",
    "        feature_extractor,\n",
    "        activity_detector=activity_detector,\n",
    "        min_activity_dur=0.05,\n",
    "        audio_dirname='audio',\n",
    "        annotation_dirname='annotations',\n",
    "        with_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write noise TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['XC370891.M.wav', 'XC78163.L.wav'], [{268}, {324}])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_birds = read_dataset_file(DATASET_BIRDS_PATH)\n",
    "dataset_birds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get noise dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Read dataset file (line in the file contains the audio filename and the associated label(s) in the following format:\n",
    "<br>`<filename>,<label1>(#<label2>...#<labelN>)`\n",
    "<br>`<filename>,<label1>(#<label2>...#<labelN>)`\n",
    "<br>..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jul/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from phaunos_ml.utils.dataset_utils import create_subset, dataset_stat_per_file, read_dataset_file\n",
    "from phaunos_ml.utils.dataug_utils import tfrecords2dataset_aug, tfrecords2tfdataset, mixup\n",
    "from phaunos_ml.utils.feature_utils import AudioSegmentExtractor\n",
    "#from phaunos_ml.utils.dataset_utils import dataset2tfrecords\n",
    "from phaunos_ml.utils import tf_utils\n",
    "from phaunos_ml.utils.tf_utils import serialized2data\n",
    "from nsb_aad.frame_based_detectors.mario_detector import MarioDetector\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/home/jul/data/xenocanto/'\n",
    "LABEL_FILENAME = '/home/jul/data/xenocanto/labels.csv'\n",
    "SUBSET_PATH = os.path.join(ROOT_PATH, 'custom_subsets')\n",
    "AUDIO_DIRNAME = 'audio/wav_22050hz_MLR'\n",
    "ANNOTATION_DIRNAME = 'annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: {60, 141}\n",
      "/home/jul/data/xenocanto/custom_subsets/subset_1570008079/subset_1570008079.csv\n"
     ]
    }
   ],
   "source": [
    "# create Xeno-Canto data subset with 5 randomly picked classes\n",
    "class_list = sorted([line.strip() for line in open(LABEL_FILENAME, 'r')])\n",
    "subset_label_set = set(np.random.choice(range(len(class_list)), 2, replace=False))\n",
    "print(f'Classes: {subset_label_set}')\n",
    "subset_filename = create_subset(\n",
    "    ROOT_PATH,\n",
    "    ['.'],\n",
    "    SUBSET_PATH,\n",
    "    audio_dirname=AUDIO_DIRNAME,\n",
    "    annotation_dirname=ANNOTATION_DIRNAME,\n",
    "    label_set=subset_label_set)\n",
    "print(subset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:00, 1085.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class index, number of files, total duration (in s)\n",
      " 60 (ardenna_pacifica), 10, 468.887\n",
      " 141 (coracias_garrulus), 9, 298.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Show dataset stats\n",
    "# Note: The total number of instances might be higher than the number of audio files because a file might have multiple labels\n",
    "d_num, d_dur = dataset_stat_per_file(ROOT_PATH, subset_filename)\n",
    "print(\"Class index, number of files, total duration (in s)\") \n",
    "for k, v in sorted(d_num.items()): \n",
    "    print(f' {k} ({class_list[k]}), {v}, {d_dur[k]:<.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_rate': 22050,\n",
       " 'win_length': 512,\n",
       " 'hop_length': 128,\n",
       " 'min_freq': 200,\n",
       " 'max_freq': 11025,\n",
       " 'clipping_threshold': 3,\n",
       " 'opening_kernel_shape': [2, 3],\n",
       " 'median_filter_shape': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configure activity detector\n",
    "config_file_mario = '/home/jul/dev/nature_sound_box/nsb_aad/configs/mario.json'\n",
    "config_mario = json.load(open(config_file_mario, 'r'))\n",
    "mario_detector = MarioDetector(config_mario)\n",
    "config_mario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure audio segment extractor\n",
    "sr = 22050\n",
    "segment_dur = 1\n",
    "segment_hop_dur = 1\n",
    "audio_ex = AudioSegmentExtractor(sr=sr, example_duration=segment_dur, example_hop_duration=segment_hop_dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  2.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate feature\n",
    "from phaunos_ml.utils.dataset_utils import dataset2tfrecords\n",
    "tfrecord_path = os.path.join(os.path.dirname(subset_filename), 'features')\n",
    "dataset2tfrecords(ROOT_PATH,                  \n",
    "                  subset_filename,\n",
    "                  tfrecord_path,\n",
    "                  feature_extractor=audio_ex,\n",
    "                  activity_detector=mario_detector,\n",
    "                  min_activity_dur=0.04,                  \n",
    "                  audio_dirname=AUDIO_DIRNAME,\n",
    "                  annotation_dirname=ANNOTATION_DIRNAME\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1002 11:23:42.366763 140554214725440 deprecation.py:323] From /home/jul/dev/phaunos_ml/phaunos_ml/utils/tf_utils.py:44: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "# check some examples\n",
    "example_filenames = random.sample(os.listdir(os.path.join(tfrecord_path, 'positive', AUDIO_DIRNAME)), 2)\n",
    "example1 = tf_utils.tfrecord2example(os.path.join(tfrecord_path, 'positive', AUDIO_DIRNAME, example_filenames[0]), audio_ex)\n",
    "example2 = tf_utils.tfrecord2example(os.path.join(tfrecord_path, 'positive', AUDIO_DIRNAME, example_filenames[1]), audio_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd4c4787e80>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_ex.plot(example1[0]['data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phaunos_ml.utils.dataset_utils import create_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training and augmentation files lists\n",
    "train_files, train_labels = read_dataset_file(\n",
    "    subset_filename,\n",
    "    prepend_path=os.path.join(tfrecord_path, 'positive'),\n",
    "    replace_ext='.tf')\n",
    "aug_files, aug_labels = read_dataset_file(\n",
    "    subset_filename,\n",
    "    prepend_path=os.path.join(tfrecord_path, 'negative'),\n",
    "    replace_ext='.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jul/data/xenocanto/custom_subsets/subset_1570008079/features/positive/audio/wav_22050hz_MLR/XC137486.R.tf, {141}\n"
     ]
    }
   ],
   "source": [
    "print(f'{train_files[3]}, {train_labels[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jul/data/xenocanto/custom_subsets/subset_1570008079/features/negative/audio/wav_22050hz_MLR/XC303133.M.tf, {60}\n"
     ]
    }
   ],
   "source": [
    "print(f'{aug_files[5]}, {aug_labels[5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60, 141]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list = sorted(list(set.union(*train_labels)))\n",
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map to dataset\n",
    "tf_train_files = tf.convert_to_tensor(train_files, dtype=dtypes.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_files = tf.data.Dataset.from_tensor_slices(tf_train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf_train_files.interleave(lambda x: tf.data.TFRecordDataset(x), cycle_length=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((1, 1, 22050), (2,), (), (2,)), types: (tf.float32, tf.float32, tf.string, tf.float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(lambda x: serialized2data(x, audio_ex.feature_shape, class_list, training=False))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_aug = tf.data.TFRecordDataset(aug_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV1 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_aug = dataset_aug.map(lambda x: serialized2data(x, audio_ex.feature_shape, class_list, training=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<lambda>() takes 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-13c198834b41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1771\u001b[0m       return DatasetV1Adapter(\n\u001b[0;32m-> 1772\u001b[0;31m           MapDataset(self, map_func, preserve_cardinality=False))\n\u001b[0m\u001b[1;32m   1773\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m       return DatasetV1Adapter(\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3188\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3189\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3190\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3191\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   3192\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   2553\u001b[0m       \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2554\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2555\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 1355\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1543\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   1546\u001b[0m         self._function_attributes)\n\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                           converted_func)\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2547\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   2548\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2549\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2550\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/phaunos_ml/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <lambda>() takes 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda feat, labels: (feat, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = create_subset('/home/jul/data/xenocanto/', ['.'], '/home/jul/', label_set=set([4,9]), audio_dirname='audio/wav_22050hz_MLR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jul/subset_1571233036/subset_1571233036.csv'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phaunos_ml.utils.dataset_utils import read_dataset_file, split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames, labels = read_dataset_file('/home/jul/data/xenocanto/', subset,audio_dirname='audio/wav_22050hz_MLR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{9},\n",
       " {9},\n",
       " {9},\n",
       " {9},\n",
       " {9},\n",
       " {4},\n",
       " {9},\n",
       " {9},\n",
       " {9},\n",
       " {4},\n",
       " {9},\n",
       " {9},\n",
       " {9},\n",
       " {9},\n",
       " {9},\n",
       " {4},\n",
       " {4},\n",
       " {9},\n",
       " {9},\n",
       " {9}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jul/subset_1571233036/subset_1571233036.train.csv written\n",
      "/home/jul/subset_1571233036/subset_1571233036.test.csv written\n"
     ]
    }
   ],
   "source": [
    "split_dataset('/home/jul/data/xenocanto/', subset,audio_dirname='audio/wav_22050hz_MLR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio/wav_22050hz_MLR/XC443243.L.wav, {9}\n",
      "audio/wav_22050hz_MLR/XC74567.L.wav, {9}\n",
      "audio/wav_22050hz_MLR/XC74568.R.wav, {9}\n",
      "audio/wav_22050hz_MLR/XC443243.R.wav, {9}\n",
      "audio/wav_22050hz_MLR/XC74569.L.wav, {9}\n",
      "audio/wav_22050hz_MLR/XC40178.R.wav, {4}\n",
      "audio/wav_22050hz_MLR/XC74572.L.wav, {9}\n",
      "audio/wav_22050hz_MLR/XC74571.R.wav, {9}\n",
      "audio/wav_22050hz_MLR/XC74570.L.wav, {9}\n",
      "audio/wav_22050hz_MLR/XC327373.R.wav, {4}\n",
      "audio/wav_22050hz_MLR/XC74571.L.wav, {9}\n",
      "audio/wav_22050hz_MLR/XC443239.L.wav, {9}\n",
      "audio/wav_22050hz_MLR/XC74568.L.wav, {9}\n",
      "audio/wav_22050hz_MLR/XC74567.R.wav, {9}\n",
      "audio/wav_22050hz_MLR/XC74572.R.wav, {9}\n",
      "audio/wav_22050hz_MLR/XC40178.L.wav, {4}\n",
      "audio/wav_22050hz_MLR/XC327373.L.wav, {4}\n",
      "audio/wav_22050hz_MLR/XC74570.R.wav, {9}\n",
      "audio/wav_22050hz_MLR/XC443239.R.wav, {9}\n",
      "audio/wav_22050hz_MLR/XC74569.R.wav, {9}\n"
     ]
    }
   ],
   "source": [
    "for f, l in zip(filenames, labels):\n",
    "    print(f'{f}, {l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phaunos_ml.utils.dataset_utils import dataset2tfrecords, dataset_stat_per_file, dataset_stat_per_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:04<00:00,  5.20it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset2tfrecords('/home/jul/data/xenocanto/', subset, \"/home/jul/features\", feature_extractor, audio_dirname='audio/wav_22050hz_MLR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 13736.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(defaultdict(int, {9: 16, 4: 4}),\n",
       " defaultdict(float, {9: 831.5024943310658, 4: 191.89551020408163}))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_stat_per_file('/home/jul/data/xenocanto/', subset, audio_dirname='audio/wav_22050hz_MLR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, array([194, 836], dtype=int32))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_stat_per_example('/home/jul/data/xenocanto/',\n",
    "                         subset,\n",
    "                         \"/home/jul/features/positive\",\n",
    "                         feature_extractor.feature_shape,\n",
    "                         [4,9],\n",
    "                         audio_dirname='audio/wav_22050hz_MLR',\n",
    "                         batch_size=1\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1022"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "831+191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
